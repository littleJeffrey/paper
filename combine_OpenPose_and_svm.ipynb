{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "651c19ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./訓練用影片/00021.MTS\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from models.with_mobilenet import PoseEstimationWithMobileNet\n",
    "from modules.keypoints import extract_keypoints, group_keypoints\n",
    "from modules.load_state import load_state\n",
    "from modules.pose import Pose, track_poses\n",
    "from val import normalize, pad_width\n",
    "\n",
    "NORMAL_LENGTH = 100\n",
    "FRAME_WIDTH = 1920\n",
    "KEYPOINTS = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "BONES_DRAW = [[0, 1], [1, 2], [1, 3], [2, 4], [3, 5], [4, 6], [5, 7]]\n",
    "BONES = [[0, 1], [2, 3], [3, 4], [5, 6], [6, 7]]\n",
    "ANGLES = [[[1, 0], 90], [[3, 2], 180], [[4, 3], 90], [[6, 5], 0], [[7, 6], 90]]\n",
    "CUT_PHOTO = 30\n",
    "\n",
    "KEYPOINTS_4dots = [0, 2, 5, 14, 15, 16, 17]\n",
    "BONES_4dots = [[0, 1]]\n",
    "ANGLES_4dots = [[[1, 0], 90], [[1, 2], 90], [[1, 5], 90]]\n",
    "json_name = '00021'\n",
    "video_name = './訓練用影片/' + json_name + '.MTS'\n",
    "print(video_name)\n",
    "kernel = 'linear'\n",
    "C = 1\n",
    "gamma = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f37c5e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = './訓練用影片/after_transform_1to15.csv'\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# #讀取訓練資料內容\n",
    "# with open(file_name, newline='') as csvfile:\n",
    "#     rows = csv.reader(csvfile)\n",
    "#     for row in rows:\n",
    "#         temp = []\n",
    "#         for i in range(len(row)-2):\n",
    "#             temp.append(float(row[i]))\n",
    "#         #將資料'左中右'轉成onehotencoding\n",
    "#         if row[-2] == 'left':\n",
    "#             temp.append(1)\n",
    "#             temp.append(0)\n",
    "#             temp.append(0)\n",
    "#         elif row[-2] == 'right':\n",
    "#             temp.append(0)\n",
    "#             temp.append(0)\n",
    "#             temp.append(1)\n",
    "#         elif row[-2] == 'middle':\n",
    "#             temp.append(0)\n",
    "#             temp.append(1)\n",
    "#             temp.append(0)\n",
    "#         #把bowing、looking、others都歸類為others\n",
    "#         if row[-1] == 'bowing' or row[-1] == 'looking' or row[-1] == 'others': y.append('others')\n",
    "#         else: y.append(row[-1])\n",
    "#         X.append(temp)\n",
    "# print(X[0])\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "# print(X[0])\n",
    "# print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a1bc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.351930629205487, -102.85932046564082, -97.80066536077324, -5.058655104867581, 99.48688372906244, -10.117310209735162, -217.522169509306, 89.36957351932728, 124.78015925340034, 124.78015925340034, -193.91511235325729, 224.26704298246278, 109.6041939387976, 214.14973277272762, 107.24401847923033, 152.47927372823614, 136.94750970764866, 137.24823151613884, 90.6489414955104, 163.55962047831983, 218.26398878588063, 189.92624550665172, 100.61965527615514, 170.3624618870691, 0, 0, 1]\n",
      "(11616, 27)\n",
      "(11616,)\n",
      "[  30.35193063 -102.85932047  -97.80066536   -5.0586551    99.48688373\n",
      "  -10.11731021 -217.52216951   89.36957352  124.78015925  124.78015925\n",
      " -193.91511235  224.26704298  109.60419394  214.14973277  107.24401848\n",
      "  152.47927373  136.94750971  137.24823152   90.6489415   163.55962048\n",
      "  218.26398879  189.92624551  100.61965528  170.36246189    0.\n",
      "    0.            1.        ]\n",
      "others\n"
     ]
    }
   ],
   "source": [
    "file_name = './訓練用影片/after_transform_1to15.csv'\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "#讀取訓練資料內容\n",
    "with open(file_name, newline='') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        \n",
    "        temp = []\n",
    "        for i in range(len(row)-2):\n",
    "            temp.append(float(row[i]))\n",
    "        #將資料'左中右'轉成onehotencoding\n",
    "        if row[-2] == 'left':\n",
    "            temp.append(1)\n",
    "            temp.append(0)\n",
    "            temp.append(0)\n",
    "        elif row[-2] == 'right':\n",
    "            temp.append(0)\n",
    "            temp.append(0)\n",
    "            temp.append(1)\n",
    "        elif row[-2] == 'middle':\n",
    "            temp.append(0)\n",
    "            temp.append(1)\n",
    "            temp.append(0)\n",
    "        #把bowing、looking、others都歸類為others\n",
    "        if row[-1] == 'bowing' or row[-1] == 'looking' or row[-1] == 'others': y.append('others')\n",
    "        else: y.append(row[-1])\n",
    "        X.append(temp)\n",
    "print(X[0])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f12d320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9761813659843123\n",
      "0.9767641996557659\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1)\n",
    "first=svm.SVC(kernel=kernel,C=C,gamma=gamma)\n",
    "first.fit(X_train,y_train)\n",
    "first.predict(X_test)\n",
    "print(first.score(X_train,y_train))\n",
    "print(first.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7e46952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = './訓練用影片/after_transform_1to15_head_and_shoulder.csv'\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# #讀取訓練資料內容\n",
    "# with open(file_name, newline='') as csvfile:\n",
    "#     rows = csv.reader(csvfile)\n",
    "#     for row in rows:\n",
    "#         temp = []\n",
    "#         for i in range(len(row)-3):\n",
    "#             temp.append(float(row[i]))\n",
    "#         #將資料'左中右'轉成onehotencoding\n",
    "#         if row[-3] == 'left':\n",
    "#             temp.append(1)\n",
    "#             temp.append(0)\n",
    "#             temp.append(0)\n",
    "#         elif row[-3] == 'right':\n",
    "#             temp.append(0)\n",
    "#             temp.append(0)\n",
    "#             temp.append(1)\n",
    "#         elif row[-3] == 'middle':\n",
    "#             temp.append(0)\n",
    "#             temp.append(1)\n",
    "#             temp.append(0)\n",
    "#         temp.append(row[-2])\n",
    "#         y.append(row[-1])\n",
    "#         X.append(temp)\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "# print(X[0])\n",
    "# print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54c6961f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-21.818181818181817' '-90.9090909090909' '-101.81818181818181'\n",
      " '-5.454545454545454' '100.0' '0.0' '-43.63636363636363'\n",
      " '-118.18181818181817' '9.09090909090909' '-118.18181818181817'\n",
      " '-65.45454545454545' '-107.27272727272727' '58.18181818181818'\n",
      " '-112.72727272727272' '103.4957332807958' '0.9090909090909091'\n",
      " '1.1818181818181819' '1.1818181818181819' '1.0727272727272728'\n",
      " '1.1272727272727272' '10.909090909090908' '5.454545454545454' '1' '0' '0'\n",
      " '1.8181818181818181']\n",
      "looking\n"
     ]
    }
   ],
   "source": [
    "file_name = './訓練用影片/after_transform_1to15_head_and_shoulder.csv'\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "#讀取訓練資料內容\n",
    "with open(file_name, newline='') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        if row[-1] != 'others':\n",
    "            temp = []\n",
    "            for i in range(len(row)-3):\n",
    "                temp.append(float(row[i]))\n",
    "            #將資料'左中右'轉成onehotencoding\n",
    "            if row[-3] == 'left':\n",
    "                temp.append(1)\n",
    "                temp.append(0)\n",
    "                temp.append(0)\n",
    "            elif row[-3] == 'right':\n",
    "                temp.append(0)\n",
    "                temp.append(0)\n",
    "                temp.append(1)\n",
    "            elif row[-3] == 'middle':\n",
    "                temp.append(0)\n",
    "                temp.append(1)\n",
    "                temp.append(0)\n",
    "            temp.append(row[-2])\n",
    "            y.append(row[-1])\n",
    "            X.append(temp)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b001a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n",
      "1\n",
      "auto\n",
      "1\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(kernel)\n",
    "print(C)\n",
    "print(gamma)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=0)\n",
    "print('1')\n",
    "second=svm.SVC(kernel=kernel,C=C,gamma=gamma)\n",
    "print('11')\n",
    "second.fit(X_train,y_train)\n",
    "print('12345')\n",
    "second_result = second.predict(X_test)\n",
    "print(second.score(X_train,y_train))\n",
    "print(second.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824bff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算兩點之間的距離\n",
    "def get_distance(A, B):\n",
    "    distance = math.pow((A[0] - B[0]), 2) + math.pow((A[1] - B[1]), 2)\n",
    "    distance = math.sqrt(distance)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算兩個向量之間的夾角\n",
    "def get_angle(first, second, angle):\n",
    "    x1 = second[0] - first[0]\n",
    "    y1 = second[1] - first[1]\n",
    "\n",
    "    if angle == 0:\n",
    "        x2 = 1\n",
    "        y2 = 0\n",
    "    elif angle == 90:\n",
    "        x2 = 0\n",
    "        y2 = 1\n",
    "    elif angle == 180:\n",
    "        x2 = -1\n",
    "        y2 = 0\n",
    "    elif angle == 270:\n",
    "        x2 = 0\n",
    "        y2 = -1\n",
    "    dot = x1*x2+y1*y2\n",
    "    det = x1*y2-y1*x2\n",
    "    theta = np.arctan2(det, dot)\n",
    "    theta = theta if theta>0 else 2*np.pi+theta\n",
    "    theta = theta*180/np.pi\n",
    "    if theta == 360: theta = 0.0\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1302bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle_version_2(first, second, third, forth):\n",
    "    x1 = second[0] - first[0]\n",
    "    y1 = second[1] - first[1]\n",
    "    x2 = forth[0] - third[0]\n",
    "    y2 = forth[1] - third[1]\n",
    "    dot = x1*x2+y1*y2\n",
    "    det = x1*y2-y1*x2\n",
    "    theta = np.arctan2(det, dot)\n",
    "    theta = theta if theta>0 else 2*np.pi+theta\n",
    "    theta = theta*180/np.pi\n",
    "    if theta == 360: theta = 0.0\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40936dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_fast(net, img, net_input_height_size, stride, upsample_ratio,\n",
    "               pad_value=(0, 0, 0), img_mean=np.array([128, 128, 128], np.float32), img_scale=np.float32(1/256)):\n",
    "    height, width, _ = img.shape\n",
    "    scale = net_input_height_size / height\n",
    "    # scaled_img = img\n",
    "    scaled_img = cv2.resize(img, (0, 0), fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "    scaled_img = normalize(scaled_img, img_mean, img_scale)\n",
    "    min_dims = [net_input_height_size, max(scaled_img.shape[1], net_input_height_size)]\n",
    "    padded_img, pad = pad_width(scaled_img, stride, pad_value, min_dims)\n",
    "\n",
    "    tensor_img = torch.from_numpy(padded_img).permute(2, 0, 1).unsqueeze(0).float()\n",
    "    tensor_img = tensor_img\n",
    "\n",
    "    tensor_img = tensor_img.cuda()\n",
    "    \n",
    "    stages_output = net(tensor_img)\n",
    "\n",
    "    stage2_heatmaps = stages_output[-2]\n",
    "    heatmaps = np.transpose(stage2_heatmaps.squeeze().cpu().data.numpy(), (1, 2, 0))\n",
    "    heatmaps = cv2.resize(heatmaps, (0, 0), fx=upsample_ratio, fy=upsample_ratio, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    stage2_pafs = stages_output[-1]\n",
    "    pafs = np.transpose(stage2_pafs.squeeze().cpu().data.numpy(), (1, 2, 0))\n",
    "    pafs = cv2.resize(pafs, (0, 0), fx=upsample_ratio, fy=upsample_ratio, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    return heatmaps, pafs, scale, pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d44c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取影片和json檔\n",
    "cap = cv2.VideoCapture(video_name)\n",
    "net = PoseEstimationWithMobileNet()\n",
    "checkpoint = torch.load('./checkpoint_iter_370000.pth', map_location='cpu')\n",
    "load_state(net, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15587318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_demo(net, image_provider, height_size):\n",
    "    net = net.eval()\n",
    "    net = net.cuda()\n",
    "    cnt = 0\n",
    "    stride = 8\n",
    "    upsample_ratio = 4\n",
    "    num_keypoints = Pose.num_kpts\n",
    "    delay = 1\n",
    "    past_time = time.time()\n",
    "    while 1:\n",
    "        now_time = time.time()\n",
    "#         print(now_time - past_time)\n",
    "        past_time = now_time\n",
    "        cnt += 1\n",
    "        ret, img = image_provider.read()\n",
    "        if not ret: break\n",
    "        orig_img = img.copy()\n",
    "        heatmaps, pafs, scale, pad = infer_fast(net, img, height_size, stride, upsample_ratio)\n",
    "\n",
    "        total_keypoints_num = 0\n",
    "        all_keypoints_by_type = []\n",
    "        for kpt_idx in range(num_keypoints):  # 19th for bg\n",
    "            total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n",
    "\n",
    "        pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n",
    "        for kpt_id in range(all_keypoints.shape[0]):\n",
    "            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n",
    "            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n",
    "        current_poses = []\n",
    "        for n in range(len(pose_entries)):\n",
    "            if len(pose_entries[n]) == 0:\n",
    "                continue\n",
    "            pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n",
    "            for kpt_id in range(num_keypoints):\n",
    "                if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n",
    "                    pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n",
    "                    pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n",
    "            pose = Pose(pose_keypoints, pose_entries[n][18])\n",
    "            current_poses.append(pose)\n",
    "\n",
    "        for pose in current_poses:\n",
    "            pose.draw(img)\n",
    "            \n",
    "        img = cv2.addWeighted(orig_img, 0.6, img, 0.4, 0)\n",
    "        for pose in current_poses:\n",
    "            cv2.rectangle(img, (pose.bbox[0], pose.bbox[1]),\n",
    "                          (pose.bbox[0] + pose.bbox[2], pose.bbox[1] + pose.bbox[3]), (0, 255, 0))\n",
    "            \n",
    "        for pose in current_poses:\n",
    "            max_x = 0\n",
    "            max_y = 0\n",
    "            min_x = 9999\n",
    "            min_y = 9999\n",
    "            temp = []\n",
    "            people = pose.keypoints\n",
    "            for i in people:\n",
    "                if i[0] != -1:\n",
    "                    if i[0] > max_x: max_x = i[0]\n",
    "                    if i[0] < min_x: min_x = i[0]\n",
    "                    if i[1] > max_y: max_y = i[1]\n",
    "                    if i[1] < min_y: min_y = i[1]\n",
    "            if people[1][0] == -1 or people[5][0] == -1: continue\n",
    "            if get_distance(people[1], people[5]) == 0: continue\n",
    "            scale = NORMAL_LENGTH / get_distance(people[1], people[5])\n",
    "            for i in KEYPOINTS:\n",
    "                if i != 1:\n",
    "                    if people[i][0] == -1:\n",
    "                        temp.append(-1)\n",
    "                        temp.append(-1)\n",
    "                    else:\n",
    "                        temp.append((people[i][0] - people[1][0]) * scale)\n",
    "                        temp.append((people[i][1] - people[1][1]) * scale)\n",
    "            for i in BONES:\n",
    "                if people[i[0]][0] == -1 or people[i[1]][0] == -1:\n",
    "                    temp.append(-1)\n",
    "                else:\n",
    "                    temp.append(get_distance(people[i[0]], people[i[1]]) * scale)\n",
    "            for i in ANGLES:\n",
    "                if people[i[0][0]][0] == -1 or people[i[0][1]][0] == -1:\n",
    "                    temp.append(-1)\n",
    "                else:\n",
    "                    temp.append(get_angle(people[i[0][0]], people[i[0][1]], i[1]))\n",
    "            if people[1][0] < (FRAME_WIDTH / 3):\n",
    "                temp.append(1)\n",
    "                temp.append(0)\n",
    "                temp.append(0)\n",
    "            elif people[1][0] > (FRAME_WIDTH / 3 * 2):\n",
    "                temp.append(0)\n",
    "                temp.append(0)\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "                temp.append(1)\n",
    "                temp.append(0)\n",
    "            temp = [temp]\n",
    "            result = first.predict(temp)\n",
    "            if result[0] =='asking' or result[0] == 'boring':\n",
    "#                 print(result[0])\n",
    "                cv2.putText(img, result[0], (int((min_x + max_x)/2), min_y-5), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "            else:\n",
    "                temp = []\n",
    "                for i in KEYPOINTS_4dots:\n",
    "                    if people[i][0] == -1:\n",
    "                        temp.append(0.0)\n",
    "                        temp.append(0.0)\n",
    "                    else:\n",
    "                        temp.append((people[i][0] - people[1][0]) * scale)\n",
    "                        temp.append((people[i][1] - people[1][1]) * scale)\n",
    "                #身體角度\n",
    "                for i in [[[1, 0], 0]]:\n",
    "                    if people[i[0][0]][0] == -1 or people[i[0][1]][0] == -1:\n",
    "                        temp.append(0.0)\n",
    "                    else:\n",
    "                        temp.append(get_angle(people[i[0][0]], people[i[0][1]], i[1]))\n",
    "                \n",
    "                #頭和肩膀的比例\n",
    "                if people[0][1] != -1: temp.append((people[1][1] - people[0][1]) / get_distance(people[1], people[5]))\n",
    "                else: temp.append(0.0)\n",
    "                \n",
    "                #眼睛和耳朵的高度(y)和肩膀的比例\n",
    "                if people[14][1] != -1: temp.append((people[1][1] - people[14][1]) / get_distance(people[1], people[5]))\n",
    "                else: temp.append(0.0)\n",
    "                if people[15][1] != -1: temp.append((people[1][1] - people[15][1]) / get_distance(people[1], people[5]))\n",
    "                else: temp.append(0.0)\n",
    "                if people[16][1] != -1: temp.append((people[1][1] - people[16][1]) / get_distance(people[1], people[5]))\n",
    "                else: temp.append(0.0)\n",
    "                if people[17][1] != -1: temp.append((people[1][1] - people[17][1]) / get_distance(people[1], people[5]))\n",
    "                else: temp.append(0.0)\n",
    "                \n",
    "                #眼睛和耳朵的高度差(調過大小的)\n",
    "                if people[14][1] != -1 and people[16][1] != -1: temp.append((people[16][1] - people[14][1]) * scale)\n",
    "                else: temp.append(0.0)\n",
    "                if people[15][1] != -1 and people[17][1]!= -1: temp.append((people[17][1] - people[15][1]) * scale)\n",
    "                else: temp.append(0.0)\n",
    "                if people[1][0] < (FRAME_WIDTH / 3):\n",
    "                    temp.append(1)\n",
    "                    temp.append(0)\n",
    "                    temp.append(0)\n",
    "                elif people[1][0] > (FRAME_WIDTH / 3 * 2):\n",
    "                    temp.append(0)\n",
    "                    temp.append(0)\n",
    "                    temp.append(1)\n",
    "                else:\n",
    "                    temp.append(0)\n",
    "                    temp.append(1)\n",
    "                    temp.append(0)\n",
    "                temp.append(scale)\n",
    "                \n",
    "                temp = [temp]\n",
    "                result = second.predict(temp)\n",
    "                cv2.putText(img, result[0], (int((min_x + max_x)/2), min_y-5), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "                \n",
    "        #img = cv2.resize(img, (1280, 720), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        if cnt % CUT_PHOTO == 0: cv2.imwrite('./results/' + json_name + '/svm_new/' + str(int(cnt/CUT_PHOTO)) + '.jpg', img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eaed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_demo(net, cap, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1223ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_demo(net, image_provider, height_size):\n",
    "#     net = net.eval()\n",
    "      net = net.cuda()\n",
    "#     cnt = 0\n",
    "#     stride = 8\n",
    "#     upsample_ratio = 4\n",
    "#     num_keypoints = Pose.num_kpts\n",
    "#     previous_poses = []\n",
    "#     delay = 1\n",
    "#     while 1:\n",
    "#         cnt += 1\n",
    "#         ret, img = image_provider.read()\n",
    "#         if not ret: break\n",
    "#         orig_img = img.copy()\n",
    "#         heatmaps, pafs, scale, pad = infer_fast(net, img, height_size, stride, upsample_ratio)\n",
    "\n",
    "#         total_keypoints_num = 0\n",
    "#         all_keypoints_by_type = []\n",
    "#         for kpt_idx in range(num_keypoints):  # 19th for bg\n",
    "#             total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n",
    "\n",
    "#         pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n",
    "#         for kpt_id in range(all_keypoints.shape[0]):\n",
    "#             all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n",
    "#             all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n",
    "#         current_poses = []\n",
    "#         for n in range(len(pose_entries)):\n",
    "#             if len(pose_entries[n]) == 0:\n",
    "#                 continue\n",
    "#             pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n",
    "#             for kpt_id in range(num_keypoints):\n",
    "#                 if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n",
    "#                     pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n",
    "#                     pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n",
    "#             pose = Pose(pose_keypoints, pose_entries[n][18])\n",
    "#             current_poses.append(pose)\n",
    "\n",
    "#         for pose in current_poses:\n",
    "#             pose.draw(img)\n",
    "        \n",
    "#         img = cv2.addWeighted(orig_img, 0.6, img, 0.4, 0)\n",
    "#         for pose in current_poses:\n",
    "#             cv2.rectangle(img, (pose.bbox[0], pose.bbox[1]),\n",
    "#                           (pose.bbox[0] + pose.bbox[2], pose.bbox[1] + pose.bbox[3]), (0, 255, 0))\n",
    "#         for pose in current_poses:\n",
    "#             #這裡辨識\n",
    "        \n",
    "#         if cnt % CUT_PHOTO == 0: cv2.imwrite('./results/' + json_name + '/CNN/CNN_' + str(int(cnt/CUT_PHOTO)) + '.jpg', img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
